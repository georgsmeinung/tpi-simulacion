[
  {
    "objectID": "tpi-simulation-in-data-science.html#simulación-y-optimización-en-ciencia-de-datos",
    "href": "tpi-simulation-in-data-science.html#simulación-y-optimización-en-ciencia-de-datos",
    "title": "Maestría en Ciencia de Datos 2024/2025",
    "section": "Simulación y Optimización en Ciencia de Datos",
    "text": "Simulación y Optimización en Ciencia de Datos"
  },
  {
    "objectID": "tpi-simulation-in-data-science.html#trabajo-práctico-integral",
    "href": "tpi-simulation-in-data-science.html#trabajo-práctico-integral",
    "title": "Maestría en Ciencia de Datos 2024/2025",
    "section": "Trabajo Práctico Integral",
    "text": "Trabajo Práctico Integral\nProfesores:\n\nDEL ROSSO, Rodrigo\nNUSKE, Ezequiel\n\nIntegrantes:\n\nCANCELAS, Martín\nFILIPUZZI, Juan Manuel\nNICOLAU, Jorge\n\n\nIntroducción\nEste Trabajo Práctico (TP) integra los contenidos vistos en las clases\n\nUnidad I – Generación de números pseudoaleatorios y Monte Carlo\nUnidad II – Bayes, cadenas de Markov y Metropolis–Hastings\nUnidad III – Simulación de eventos discretos (SED)\nUnidad IV – Procesos continuos (NHPP, CTMC, SDE)\nUnidad V – Reacciones químicas estocásticas: Gillespie SSA y Next Reaction Method\n\nEl objetivo es que el alumno implemente técnicas de simulación, compare métodos, valide sus resultados y presente visualizaciones claras.\n\n\nSobre el código base\nEl código base propuesto en el enunciado en R se ha transformado a Python y se encuentra en el anexo al final del trabajo.\n\n\nConfiguración\nPara el presente trabajo se utilizan los siguientes parámetros globales y semilla\n\n# CONFIGURACIÓN\n# Parámetros (LCG estándar de C++ minstd_rand)\nlgc_a, lgc_c, lgc_m = 48271, 0, 2**31 - 1\n# Semilla\nrnd_seed = 2371\n\n\n\nParte 1 - Generación de Números Pseudoaleatorios y Monte Carlo\n\nImplementación de un Generador Congruencial Lineal (LCG)\nLa implementación de un Generador Congruencial Lineal (LCG) se fundamenta en un algoritmo iterativo y determinista regido por la relación de recurrencia\n\\[X_{n+1} = (aX_n + c) \\mod m\\]\nmediante la cual se produce una secuencia de números pseudoaleatorios a partir de un valor inicial denominado semilla (\\(X_0\\)). El proceso requiere la definición de tres constantes enteras —el multiplicador (\\(a\\)), el incremento (\\(c\\)) y el módulo (\\(m\\))— y opera calculando el siguiente valor de la serie al multiplicar el estado actual por \\(a\\), sumar \\(c\\) y obtener el residuo de la división por \\(m\\), resultando en una sucesión periódica que, si bien carece de aleatoriedad verdadera, es computacionalmente eficiente y totalmente reproducible si se mantienen los mismos parámetros iniciales.\nAl usar operaciones aritméticas básicas, es extremadamente rápido computacionalmente. Como hay un número finito de resultados posibles (de \\(0\\) a \\(m-1\\)), la secuencia eventualmente se repetirá. A esto se le llama el “periodo”. Por otra parte si se usa la misma semilla (\\(X_0\\)), se obtendrá exactamente la misma secuencia de números. Esto es útil para “debugging” o reproducir simulaciones científicas, pero malo para la seguridad. No es seguro criptográficamente: No se debe usar para contraseñas o claves de seguridad, ya que es relativamente fácil predecir los siguientes números analizando la secuencia previa.\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Implementación del LCG\ndef lcg_generator(seed, a, c, m, n):\n    numbers = []\n    x = seed\n    for _ in range(n):\n        x = (a * x + c) % m\n        # Normalizar a [0, 1]\n        numbers.append(x / m) \n\n    return numbers\n\nPara evaluar la calidad de los números pseudoaleatorios generados por uel LCG, es necesario verificar dos propiedades fundamentales: Uniformidad e Independencia. A continuación, se detalla la lógica de implementación y el código en Python para las tres herramientas solicitadas.\n\n\nHistograma\nEl histograma visualiza la distribución de frecuencia de los números generados. Para un buen generador, esperamos una distribución uniforme (plana), lo que significa que cada intervalo del rango tiene aproximadamente la misma probabilidad de contener un número.\n\ndatos = lcg_generator(seed=rnd_seed, a=lgc_a, c=lgc_c, m=lgc_m, n=5000)\n\n# Histograma\nplt.figure(figsize=(10, 3))\nplt.hist(datos, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\nplt.title('Histograma de Uniformidad')\nplt.show()\n\n\n\n\n\n\n\n\nLa presencia de alturas similares en todas las barras (“bins”) del histograma indica que el Generador Congruencial Lineal (LCG) está cumpliendo satisfactoriamente con la propiedad de uniformidad, lo que significa que cada sub-intervalo del rango tiene una probabilidad casi idéntica de contener un número generado. Esta distribución “plana” o rectangular sugiere que el algoritmo recorre el espacio muestral sin sesgos evidentes ni favoritismos hacia ciertos valores; sin embargo, es crucial notar que estas variaciones leves deben ser producto del azar natural (pequeñas fluctuaciones son esperadas y saludables), y aunque este patrón valida la equiprobabilidad, por sí solo no garantiza la independencia de los datos (ausencia de patrones secuenciales), por lo que un histograma visualmente equilibrado es una condición necesaria, pero no suficiente, para aprobar un generador.\n\n\nRuns Test (Prueba de Rachas/Corridas)\nEsta prueba verifica la independencia analizando la secuencia de oscilaciones. Una “racha” es una secuencia ininterrumpida de números crecientes o decrecientes.\nPara la lógica de Implementación (con Corridas Arriba/Abajo) se toma la secuencia \\(u_1, u_2, \\dots, u_n\\). Se crea una nueva secuencia binaria basada en si el valor actual es mayor o menor que el anterior (\\(+\\) si \\(u_i &lt; u_{i+1}\\), \\(-\\) si \\(u_i &gt; u_{i+1}\\)). Luego se cuenta el número total de rachas (cambios de \\(+\\) a \\(-\\) o viceversa). Se calcual el estadístico Z comparando el número de rachas obtenido con el esperado teóricamente usando la aproximación normal para muestras grandes (\\(N &gt; 20\\)).\n\\[\\mu_R = \\frac{2N - 1}{3}\\] \\[\\sigma_R^2 = \\frac{16N - 29}{90}\\] \\[Z = \\frac{R - \\mu_R}{\\sigma_R}\\]\nSi el valor absoluto de \\(Z\\) (\\(|Z|\\)) es mayor que el valor crítico (ej. \\(1.96\\) para un 95% de confianza), se rechaza la hipótesis de independencia.\n\n# Runs Test\nruns = 1 # Empieza la primera racha\nfor i in range(len(datos) - 1):\n    # Si la dirección cambia respecto al anterior, es nueva racha\n    if i &gt; 0:\n        prev_diff = datos[i] - datos[i-1]\n        curr_diff = datos[i+1] - datos[i]\n        # Si el producto es negativo, hubo cambio de signo (dirección)\n        if prev_diff * curr_diff &lt; 0:\n            runs += 1\n\nexpected_runs = (2 * len(datos) - 1) / 3\nprint(f\"Rachas observadas: {runs}\")\nprint(f\"Rachas esperadas: {expected_runs:.2f}\")\n\nRachas observadas: 3325\nRachas esperadas: 3333.00\n\n\nLa cercanía entre las rachas observadas y las esperadas revela una discrepancia numérica mínima, lo cual sugiere que el Generador Congruencial Lineal (LCG) cumple satisfactoriamente con la propiedad de independencia estadística. Este resultado indica que la secuencia de números fluctúa (asciende y desciende) con una frecuencia consistente con el azar puro, descartando la presencia de patrones de dependencia serial; al no existir una desviación significativa (la diferencia es muy pequeña considerando el tamaño de la muestra), el valor estadístico \\(Z\\) resultante sería muy cercano a cero, lo que impide rechazar la hipótesis nula y permite concluir que los datos no están correlacionados entre sí, validando el motor como un generador robusto en términos de oscilación.\n\n\nGráfico de Triples (Spectral Test Visual)\nEsta es una visualización en 3D para detectar correlaciones seriales. Los generadores LCG malos tienden a concentrar los puntos en planos discretos en lugar de llenar el espacio uniformemente (fenómeno conocido como planos de Marsaglia).\nEl gráfico de triples opera bajo la lógica de visualización del espacio de fases para detectar correlaciones seriales de largo alcance, mapeando tríadas consecutivas de la secuencia generada \\((u_n, u_{n+1}, u_{n+2})\\) como coordenadas espaciales \\((x, y, z)\\) en un cubo tridimensional. La premisa fundamental es que, si los números fueran verdaderamente independientes, los puntos deberían llenar el volumen de manera caótica y uniforme como una “nube de polvo”; sin embargo, debido a la naturaleza lineal de la fórmula \\(X_{n+1} = (aX_n + c)\\), los LCGs deficientes exhiben una estructura cristalina donde los puntos se alinean rígidamente en un número finito de planos paralelos (fenómeno conocido como planos de Marsaglia), revelando visualmente que la aleatoriedad es solo aparente y que existen dependencias matemáticas estrictas entre valores sucesivos.\n\n# Esto estira el lienzo hacia la derecha.\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(111, projection='3d')\n\n# Crear tripletas\nx_vals = datos[:-2]\ny_vals = datos[1:-1]\nz_vals = datos[2:]\n\nax.scatter(x_vals, y_vals, z_vals, s=1, alpha=0.5)\n\nax.set_title('Gráfico de Triples (Correlación Serial)')\nax.set_xlabel('U(i)')\nax.set_ylabel('U(i+1)')\nax.set_zlabel('U(i+2)')\nplt.subplots_adjust(right=0.75, left=0.1, bottom=0.1, top=0.9)\n\nplt.show()\n\n\n\n\n\n\n\n\nLa observación de una nube de puntos dispersa y volumétrica que llena el cubo de manera homogénea se interpreta como una validación exitosa de la calidad espectral del generador, indicando que la correlación serial entre ternas consecutivas \\((u_n, u_{n+1}, u_{n+2})\\) es despreciable o inexistente para fines prácticos. Visualmente, esto contrasta con los generadores deficientes que agrupan los puntos en “rebanadas” o planos paralelos separados; por el contrario, una distribución uniforme implica que el algoritmo posee un periodo lo suficientemente largo y unos parámetros adecuados para “romper” la estructura reticular visible, garantizando que no existen dependencias geométricas fuertes y haciendo al generador apto para simulaciones Monte Carlo multidimensionales.\nLa estimación del valor de \\(\\pi\\) mediante el método de Monte Carlo utiliza el Generador Congruencial Lineal (LCG) para producir pares de coordenadas \\((x, y)\\) uniformemente distribuidas en el intervalo \\([0, 1)\\), simulando el lanzamiento aleatorio de puntos sobre un cuadrado unitario que contiene un cuarto de círculo inscrito. El procedimiento se fundamenta en la geometría probabilística: dado que el área del cuarto de círculo es \\(\\pi/4\\) y el área del cuadrado es \\(1\\), la probabilidad de que un punto caiga dentro del círculo es exactamente \\(\\pi/4\\); por consiguiente, al verificar cuántos puntos cumplen la condición \\(x^2 + y^2 \\le 1\\) y dividir esa cantidad por el número total de puntos generados, se obtiene una proporción que, multiplicada por \\(4\\), aproxima el valor de \\(\\pi\\), sirviendo esto a su vez como una prueba funcional de la calidad del LCG, ya que un generador sesgado o correlacionado (como el que forma líneas en el gráfico de triples) arrojará un valor de \\(\\pi\\) incorrecto al no cubrir el área uniformemente.\nLógica de Implementación 1. Generación de Pares: Se utiliza el LCG para obtener dos números consecutivos normalizados (\\(u_i, u_{i+1}\\)) que actúan como coordenadas \\(x\\) e \\(y\\). 2. Condición Geométrica: Se calcula la distancia al origen (\\(d = x^2 + y^2\\)). 3. Conteo: Si \\(d \\le 1\\), el punto está “dentro” del círculo (Acierto). 4. Cálculo Final: \\(\\pi \\approx 4 \\times \\frac{\\text{Aciertos}}{\\text{Total de Puntos}}\\).\n\n# Función Monte Carlo con Gráfico y Retorno de Valor\ndef estimar_y_graficar_pi(n_puntos):   \n    # Se generan los números necesarios (2 por punto)\n    s, a, c, m = rnd_seed, lgc_a, lgc_c, lgc_m\n    lista_completa = lcg_generator(s, a, c, m , n_puntos * 2)\n    iterador_numeros = iter(lista_completa)\n    \n    # Listas para guardar coordenadas (visualización)\n    inside_x, inside_y = [], []\n    outside_x, outside_y = [], []\n    \n    dentro_count = 0\n    \n    for _ in range(n_puntos):\n        # Extraer par (x, y)\n        x = next(iterador_numeros)\n        y = next(iterador_numeros)\n        \n        # Clasificar\n        if x**2 + y**2 &lt;= 1.0:\n            dentro_count += 1\n            inside_x.append(x)\n            inside_y.append(y)\n        else:\n            outside_x.append(x)\n            outside_y.append(y)\n            \n    # Estimación del valor\n    pi_estimado = 4 * (dentro_count / n_puntos)\n\n    # GRAFICO CONTEO\n    plt.figure(figsize=(6, 6))\n    \n    # Puntos dentro (Azul) y fuera (Rojo)\n    plt.scatter(inside_x, inside_y, color='dodgerblue', s=1, label='Dentro')\n    plt.scatter(outside_x, outside_y, color='salmon', s=1, label='Fuera')\n    \n    # Arco del círculo (estético)\n    t = np.linspace(0, np.pi/2, 100)\n    plt.plot(np.cos(t), np.sin(t), 'k-', lw=2)\n    \n    plt.xlim(0, 1); plt.ylim(0, 1)\n    plt.gca().set_aspect('equal')\n    plt.title(f\"Monte Carlo LCG (N={n_puntos})\\nPi estimado: {pi_estimado}\")\n    plt.legend(loc=\"upper right\")\n    plt.show()\n    \n    # --- RETORNO ESTIMACIÓN ---\n    return pi_estimado\n\n# Ejecución con diez mil puntos\nn = 10000\npi_val = estimar_y_graficar_pi(n)\n\nprint(f\"Puntos procesados: {n}\")\nprint(f\"Valor estimado de Pi: {pi_val}\")\nprint(f\"Diferencia real: {abs(pi_val - 3.14159265):.6f}\")\n\n\n\n\n\n\n\n\nPuntos procesados: 10000\nValor estimado de Pi: 3.1496\nDiferencia real: 0.008007\n\n\n\n\n\nParte 2 - Metropolis–Hastings y Bayesian Inference\nLa relación entre el algoritmo de Metropolis-Hastings y la inferencia bayesiana es fundamentalmente instrumental, donde el primero actúa como la solución computacional para los desafíos analíticos planteados por el segundo. La inferencia bayesiana busca estimar la distribución posterior de parámetros desconocidos, denotada como \\(P(\\theta | D)\\), mediante la aplicación del Teorema de Bayes. No obstante, este proceso conlleva frecuentemente el cálculo de una constante de normalización —la evidencia marginal— que implica resolver integrales multidimensionales analíticamente intratables, lo cual impide la obtención directa de la distribución posterior en modelos complejos.\nEl algoritmo de Metropolis-Hastings, perteneciente a la familia de métodos de Monte Carlo vía Cadenas de Markov (MCMC), se distingue por su capacidad para generar muestras de una distribución de probabilidad objetivo sin necesidad de conocer su constante de normalización. El algoritmo opera construyendo una cadena de Markov que converge asintóticamente a la distribución deseada, requiriendo únicamente una función que sea proporcional a dicha densidad objetivo para evaluar los ratios de aceptación de las muestras propuestas.\nEn consecuencia, la conexión crítica reside en que la distribución posterior no normalizada en la estadística bayesiana es proporcional al producto de la función de verosimilitud y la distribución a priori (\\(Likelihood \\times Prior\\)). Dado que Metropolis-Hastings puede operar bajo condiciones de proporcionalidad, este algoritmo permite muestrear la distribución posterior y realizar inferencias sobre los parámetros sin tener que calcular la integral de la evidencia marginal, haciendo viable el análisis bayesiano en escenarios de alta dimensionalidad donde las soluciones cerradas son imposibles.\n\nPosterior beta analítica\nSea una moneda con 10 lanzamientos y 7 caras, para obtener una posterior \\(\\text{Beta}(8,4)\\) a partir de 7 caras (\\(k=7\\)) y 3 cruces (\\(n-k=3\\)), debemos asumir un prior Uniforme o \\(\\text{Beta}(1,1)\\). En la inferencia Bayesiana, demode que si se usa un Prior Beta y un Likelihood Binomial, el Posterior siempre es otra Beta:\n\nLikelihood (Verosimilitud): \\(P(X|\\theta) \\propto \\theta^7 (1-\\theta)^3\\)\nPrior (A priori): \\(P(\\theta) \\sim \\text{Beta}(1,1) \\propto 1\\)\nPosterior (A posteriori): \\(P(\\theta|X) \\propto \\theta^{7+1-1} (1-\\theta)^{3+1-1} = \\theta^7 (1-\\theta)^3 \\rightarrow \\text{Beta}(8,4)\\)\n\nEn términos de Python:\n\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport arviz as az\n\n# Funciones del modelo\ndef log_prior(theta):\n    \"\"\"\n    Prior Beta(1,1) (Uniforme en [0, 1]).\n    Retorna 0 si está en rango (log(1)), -inf si no.\n    \"\"\"\n    if 0 &lt;= theta &lt;= 1:\n        return 0.0\n    return -np.inf\n\ndef log_likelihood(theta, heads, trials):\n    \"\"\"\n    Log-Likelihood Binomial.\n    \"\"\"\n    if theta &lt; 0 or theta &gt; 1:\n        return -np.inf\n    # Proporcional a theta^k * (1-theta)^(n-k)\n    return (heads * np.log(theta)) + ((trials - heads) * np.log(1 - theta))\n\ndef log_posterior(theta, heads, trials):\n    lp = log_prior(theta)\n    if not np.isfinite(lp):\n        return -np.inf\n    return lp + log_likelihood(theta, heads, trials)\n\nComo el objetivo es obtener exactamente \\(\\text{Beta}(8,4)\\) con 7 caras y 3 cruces, implícitamente se está asumiendo que no se aporta información previa (el 1 inicial de la Beta actúa como un “neutro” o punto de partida cero en términos de influencia).\n\n# Configuración del Problema\nnp.random.seed(rnd_seed)\n\n# Datos observados: 10 lanzamientos, 7 caras\nn_trials = 10\nn_heads = 7\n\n# Parámetros del algoritmo MCMC\nn_chains = 4        # Solicitado explícitamente para R-hat\nn_samples = 5000    # Muestras por cadena\nburnin = 1000       # Periodo de calentamiento (burn-in)\nstep_size = 0.1     # Desviación estándar de la propuesta (Proposal width)\n\n# Algoritmo Metropolis-Hastings\n\ndef metropolis_hastings(n_samples, n_chains, heads, trials, step_size):\n    chains = []\n    \n    print(f\"Iniciando muestreo con {n_chains} cadenas...\")\n    \n    for chain_idx in range(n_chains):\n        samples = []\n        # Punto de inicio aleatorio para cada cadena\n        current_theta = np.random.uniform(0.1, 0.9)\n        current_log_post = log_posterior(current_theta, heads, trials)\n        \n        for i in range(n_samples + burnin):\n            # 1. Propuesta: Random Walk (Normal centrada en theta actual)\n            proposal = np.random.normal(current_theta, step_size)\n            \n            # 2. Calcular Log-Posterior de la propuesta\n            proposal_log_post = log_posterior(proposal, heads, trials)\n            \n            # 3. Ratio de Aceptación (en escala logarítmica para estabilidad)\n            # r = p(new)/p(old). log(r) = log(p(new)) - log(p(old))\n            log_ratio = proposal_log_post - current_log_post\n            \n            # 4. Decisión de aceptación\n            if np.log(np.random.rand()) &lt; log_ratio:\n                current_theta = proposal\n                current_log_post = proposal_log_post\n            \n            # Guardar solo después del burn-in\n            if i &gt;= burnin:\n                samples.append(current_theta)\n        \n        chains.append(samples)\n        print(f\"Cadena {chain_idx + 1} completada.\")\n        \n    return np.array(chains)\n\n# Ejecutar el sampler\nsamples, chains, heads, trials = n_samples, n_chains, n_heads, n_trials\nchains = metropolis_hastings(samples, chains, heads, trials, step_size)\n\n# Convertir a objeto InferenceData de Arviz para facilitar diagnósticos\nidata = az.from_dict(posterior={\"theta\": chains})\n\nIniciando muestreo con 4 cadenas...\nCadena 1 completada.\nCadena 2 completada.\nCadena 3 completada.\nCadena 4 completada.\n\n\n\n\nDiagnósticos Obligtatorios\n\n\nTraceplot\nEl Traceplot permite visualizar la evolución temporal de las cadenas de Markov, facilitando la verificación inmediata de la convergencia asintótica y la calidad del muestreo. A través de este gráfico se evalúa si el algoritmo ha alcanzado la estacionariedad (oscilando alrededor de un valor estable sin tendencias) y si existe una mezcla adecuada del espacio de parámetros (exploración eficiente), lo cual es indispensable para validar que las muestras obtenidas son representativas de la distribución posterior objetivo y descartar problemas como una alta autocorrelación o una configuración errónea del tamaño de paso.\n\n# Traceplot y Densidad (Histograma implícito en kde)\n# Arviz genera automáticamente \n# Traceplot a la derecha y la densidad a la izquierda\naz.plot_trace(idata)\ngraph_title = \"Traceplot (Derecha) y Densidad Posterior (Izquierda)\"\nplt.suptitle(graph_title, y=2.05, fontsize=12)\nplt.subplots_adjust(top=.75)\nplt.tight_layout(rect=[0, 0, 1, 2])\nplt.show()\n\n\n\n\n\n\n\n\nEl gráfico confirma la convergencia exitosa y robusta del algoritmo Metropolis-Hastings, validando la calidad de la inferencia realizada. En el panel derecho (Traceplot), se observa una oscilación densa y constante alrededor de un eje central sin tendencias visibles —patrón “oruga peluda”—, lo cual demuestra que las cuatro cadenas han alcanzado la estacionariedad y exploran el espacio de parámetros con una mezcla eficiente y homogénea. Corroborando esto, el panel izquierdo (Densidad Posterior) exhibe una superposición casi perfecta de las distribuciones estimadas por cada cadena, indicando consistencia interna (bajo R-hat) y revelando una moda centrada aproximadamente en 0.7, valor que coincide con el máximo teórico esperado para la distribución Beta(8,4).\n\n\nAutocorrelación\nEl análisis de la autocorrelación permite cuantificar la dependencia serial inherente entre las muestras generadas por la cadena de Markov, dado que los algoritmos MCMC producen, por definición, observaciones correlacionadas en lugar de independientes. Este diagnóstico es crítico para evaluar la eficiencia del muestreo (mixing), ya que una persistencia alta de la correlación a través de múltiples retardos (lags) indica una exploración lenta del espacio de parámetros y reduce el tamaño de muestra efectivo (ESS), lo que alertaría sobre la necesidad de incrementar el número de iteraciones o ajustar el tamaño de paso para garantizar que la inferencia estadística sobre la posterior sea fiable y precisa.\n\n# Autocorrelación\nfig, axes = plt.subplots(2, 2, figsize=(10, 6))\naz.plot_autocorr(idata, max_lag=20, ax=axes)\nplt.suptitle(\"Gráfico de Autocorrelación\", fontsize=16)\nplt.tight_layout(rect=[0, 0, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\nLos gráficos de autocorrelación revelan una persistente dependencia serial entre las muestras sucesivas, evidenciada por un decaimiento lento de las barras que mantienen valores significativos incluso después de 15 a 20 retardos (lags). Este comportamiento, consistente en las cuatro cadenas analizadas, indica una eficiencia de mezcla (mixing) moderada y una exploración del espacio de parámetros con cierta “viscosidad”, lo cual reduce el Tamaño de Muestra Efectivo (ESS) e implica que, para fines de inferencia estadística robusta, la cantidad de información independiente real es considerablemente menor al número total de iteraciones computadas.\n\n\nHistograma vs Analítica Beta(8,4)\nLa superposición del histograma de frecuencias empíricas frente a la curva analítica de la distribución Beta es una prueba definitiva de validación, aprovechando que el modelo Beta-Binomial posee una solución cerrada conocida que sirve como “verdad fundamental” (ground truth). Este diagnóstico visual permite confirmar rigurosamente que el algoritmo Metropolis-Hastings está muestreando fielmente de la distribución objetivo y no de una aproximación errónea, verificando así que la lógica computacional, la función de verosimilitud y el mecanismo de aceptación/rechazo han sido implementados con exactitud matemática y que el muestreador recupera la geometría correcta de la posterior sin sesgos.\n\n# Histograma vs Analítica Beta(8,4)\nplt.figure(figsize=(10, 6))\n\n# Aplanar las cadenas para el histograma\nflat_samples = chains.flatten()\n\n# Histograma de muestras MCMC\nplt.hist(\n    flat_samples,\n    bins=50,\n    density=True,\n    alpha=0.6,\n    color='skyblue',\n    label='Muestras MCMC',\n    edgecolor='black'\n)\n\n# Curva Analítica Real Beta(8,4)\nx = np.linspace(0, 1, 1000)\n\n# Posterior analítica: 7 caras + 1, 3 cruces + 1\npdf_true = stats.beta.pdf(x, 8, 4)\n\nplt.plot(x, pdf_true, 'r-', lw=3, label='Analítica: Beta(8,4)')\n\nplt.title(\"Diagnóstico: Histograma MCMC vs Curva Real Beta(8,4)\")\nplt.xlabel(r\"$\\theta$ (Probabilidad de cara)\")\nplt.ylabel(\"Densidad\")\nplt.legend()\nplt.grid(alpha=0.3)\nplt.show()\n\n\n\n\n\n\n\n\nEl gráfico evidencia una correspondencia altamente satisfactoria entre la distribución empírica generada por el algoritmo (histograma azul) y la solución analítica teórica (curva roja), demostrando la exactitud de la implementación. La alineación precisa de las frecuencias de las barras con el perfil de la función de densidad Beta(8,4) confirma que el muestreador ha logrado capturar fielmente la estructura probabilística de la posterior, reproduciendo correctamente tanto la ubicación de la moda en torno a 0.7 como la dispersión asociada, lo cual valida que las muestras obtenidas son estadísticamente representativas de la distribución objetivo y legitima el uso de la simulación para la inferencia paramétrica.\n\n\nR-hat con 4 cadenas y ESS (Effective Sample Size)\nLas métricas R-hat y ESS (Tamaño de Muestra Efectivo) proporcionan una validación cuantitativa y objetiva de la fiabilidad y precisión de la simulación, superando las limitaciones de la inspección visual. El estadístico R-hat resulta indispensable al utilizar múltiples cadenas para verificar matemáticamente la convergencia global, asegurando a través de la comparación de varianzas que el algoritmo no ha quedado atrapado en óptimos locales; simultáneamente, el ESS es crítico para cuantificar el volumen real de información independiente generada descontando la autocorrelación, garantizando así que la estimación de la posterior posea un error estándar de Monte Carlo lo suficientemente reducido para ser estadísticamente válida.\n\n# R-hat y ESS (Effective Sample Size)\nsummary = az.summary(idata, kind=\"diagnostics\")\n\nprint(\"-\" * 40)\nprint(\"DIAGNÓSTICOS NUMÉRICOS\")\nprint(\"-\" * 40)\nprint(summary)\nprint(\"-\" * 40)\n\n# Verificación explicita de valores\nr_hat_val = summary.loc['theta', 'r_hat']\ness_val = summary.loc['theta', 'ess_bulk']\n\nprint(f\"R-hat obtenido (Ideal &lt; 1.01): {r_hat_val:.4f}\")\nprint(f\"ESS (Effective Sample Size): {ess_val:.1f}\")\n\n----------------------------------------\nDIAGNÓSTICOS NUMÉRICOS\n----------------------------------------\n       mcse_mean  mcse_sd  ess_bulk  ess_tail  r_hat\ntheta      0.003    0.002    1691.0    1971.0    1.0\n----------------------------------------\nR-hat obtenido (Ideal &lt; 1.01): 1.0000\nESS (Effective Sample Size): 1691.0\n\n\nLos diagnósticos numéricos validan la robustez técnica de la simulación, destacando un estadístico R-hat de 1.0 que confirma la convergencia perfecta de las cadenas y su indistinguibilidad estadística. Por su parte, el Tamaño de Muestra Efectivo (ESS) de 1691.0, aunque inferior al total de iteraciones debido a la correlación serial, resulta suficiente para garantizar estimaciones estables de la tendencia central, lo cual, sumado a un error estándar de Monte Carlo (mcse) marginal de 0.003, asegura que la precisión de la inferencia sobre la posterior es elevada y que el error introducido por el método de muestreo es despreciable.\n\n\n\nParte 3 - Simulación de Eventos Discretos (M/M/1 o M/M/c)\nPara implementar esta simulación, el motor central debe basarse en una Lista de Eventos Futuros (LEF) ordenada cronológicamente y una variable de reloj (\\(T_{now}\\)). El tiempo no avanza de forma continua, sino que “salta” discretamente al instante del evento más próximo en la lista. Inicialmente, se genera la primera llegada aleatoria (usando la tasa \\(\\lambda=10\\)) y se inserta en la LEF; el ciclo de simulación consiste en extraer repetidamente el evento de menor tiempo de la lista, actualizar el reloj a ese instante y ejecutar la lógica de cambio de estado correspondiente hasta que \\(T_{now}\\) supere las 8 horas.\nLa lógica de estado maneja dos eventos principales: Llegada y Salida. Al procesar una Llegada, se programa inmediatamente la siguiente llegada futura y se evalúan los servidores: si hay alguno libre (de los \\(c\\) disponibles), se ocupa y se calcula una duración de servicio (con tasa \\(\\mu=4\\)) para insertar un evento de Salida en la LEF; si todos están ocupados, se incrementa el contador de la cola. Por otro lado, al procesar una Salida, se libera el servidor, pero si la cola no está vacía, se decrementa inmediatamente para ingresar al siguiente cliente al servicio, generando su respectivo evento de finalización futuro.\n\nSimulación 8 horas de un sistemas de colas\nEsta es una implementaciónen Python de una simulación de eventos discretos (DES) utilizando una Lista de Eventos Futuros (LEF) implementada con una cola de prioridad (heapq). El código está diseñado para soportar tanto M/M/1 (1 servidor) como M/M/c (múltiples servidores), pero además tenemos estos parámetros:\n\n\\(\\lambda\\) (Tasa de llegadas): 10 clientes/hora.\n\\(\\mu\\) (Tasa de servicio): 4 clientes/hora.\n\\(c\\) (Servidores): Variable.\n\nEs importante resaltar que si usamos \\(c=1\\) (M/M/1), el sistema será inestable porque la tasa de llegada (10) es mayor que la capacidad de servicio (4). La cola crecerá infinitamente. Para un sistema estable, necesitamos \\(c \\ge 3\\) (capacidad 12 &gt; 10). Por esto se ha configurado el código por defecto con NUM_SERVIDORES = 3, pero puede cambiarse a 1 para observar cómo se satura.\n\nimport random\nimport heapq\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport numpy as np\nfrom IPython.display import Image, display\n\nclass SimulacionMMC_Log:\n    def __init__(self, tiempo_max, tasa_llegada,\n                 tasa_servicio, n_servidores):\n        # Ajustamos los parámetros iniciales\n        self.tiempo_max = tiempo_max\n        self.tasa_llegada = tasa_llegada\n        self.tasa_servicio = tasa_servicio\n        self.n_servidores = n_servidores\n        \n        # Estado del sistema\n        self.reloj = 0.0\n        self.num_en_cola = 0\n        self.servidores_ocupados = 0\n        self.lef = []  # Lista de Eventos Futuros\n        \n        # Estadísticas y Acumuladores\n        self.total_llegadas = 0\n        self.total_atendidos = 0\n        self.area_cola = 0.0      # Para calcular Lq\n        self.area_ocupados = 0.0  # Para calcular utilización\n        self.tiempo_ultimo_evento = 0.0\n        \n        # Historial para Animación\n        self.historia = [(0.0, 0, 0)]\n\n    def actualizar_estadisticas(self, tiempo_actual):\n        \"\"\"Calcula áreas bajo la curva antes de cambiar estado.\"\"\"\n        delta_t = tiempo_actual - self.tiempo_ultimo_evento\n        self.area_cola += self.num_en_cola * delta_t\n        self.area_ocupados += self.servidores_ocupados * delta_t\n        self.tiempo_ultimo_evento = tiempo_actual\n\n    def correr(self):\n        # Programar primera llegada\n        t_llegada = random.expovariate(self.tasa_llegada)\n        heapq.heappush(self.lef, (t_llegada, 0))  # 0 = LLEGADA\n        \n        msg = (f\"--- Iniciando Simulación M/M/{self.n_servidores} \"\n               f\"por {self.tiempo_max} horas ---\")\n        print(msg)\n        \n        while self.reloj &lt; self.tiempo_max and self.lef:\n            tiempo_evento, tipo_evento = heapq.heappop(self.lef)\n            \n            if tiempo_evento &gt; self.tiempo_max:\n                # Actualizar hasta tiempo final exacto\n                self.actualizar_estadisticas(self.tiempo_max)\n                self.reloj = self.tiempo_max\n                break\n            \n            # 1. Actualizar estadísticas\n            self.actualizar_estadisticas(tiempo_evento)\n            \n            # 2. Avanzar reloj\n            self.reloj = tiempo_evento\n            \n            # 3. Procesar evento\n            if tipo_evento == 0:  # LLEGADA\n                self.procesar_llegada()\n            else:  # SALIDA\n                self.procesar_salida()\n            \n            # 4. Guardar foto para la animación\n            self.historia.append((\n                self.reloj,\n                self.num_en_cola,\n                self.servidores_ocupados\n            ))\n\n        # AL FINALIZAR EL BUCLE: MOSTRAR RESULTADOS\n        self.reporte_final()\n\n    def procesar_llegada(self):\n        self.total_llegadas += 1\n        prox = self.reloj + random.expovariate(self.tasa_llegada)\n        heapq.heappush(self.lef, (prox, 0))\n        \n        if self.servidores_ocupados &lt; self.n_servidores:\n            self.servidores_ocupados += 1\n            t_salida = self.reloj + random.expovariate(\n                self.tasa_servicio\n            )\n            heapq.heappush(self.lef, (t_salida, 1))\n        else:\n            self.num_en_cola += 1\n\n    def procesar_salida(self):\n        self.total_atendidos += 1\n        if self.num_en_cola &gt; 0:\n            self.num_en_cola -= 1\n            t_salida = self.reloj + random.expovariate(\n                self.tasa_servicio\n            )\n            heapq.heappush(self.lef, (t_salida, 1))\n        else:\n            self.servidores_ocupados -= 1\n\n    def reporte_final(self):\n        print(\"\\n\" + \"=\"*40)\n        print(\"      RESULTADOS DE LA SIMULACIÓN\")\n        print(\"=\"*40)\n        print(f\"Tiempo simulado: {self.reloj:.2f} horas\")\n        print(f\"Total llegadas:  {self.total_llegadas}\")\n        print(f\"Total atendidos: {self.total_atendidos}\")\n        print(\"-\" * 40)\n        \n        # Cálculos de promedios\n        lq = self.area_cola / self.reloj\n        \n        prom_ocupados = self.area_ocupados / self.reloj\n        utilizacion = prom_ocupados / self.n_servidores\n        \n        # Wq usando fórmula de Little\n        lambda_real = self.total_llegadas / self.reloj\n        wq = lq / lambda_real if lambda_real &gt; 0 else 0\n        \n        print(f\"Longitud prom cola (Lq): {lq:.4f} clientes\")\n        print(f\"Tiempo prom cola (Wq): {wq*60:.2f} minutos\")\n        print(f\"Servidores ocupados (prom): {prom_ocupados:.2f}\")\n        print(f\"Utilización (Rho): {utilizacion*100:.2f}%\")\n        print(\"=\"*40 + \"\\n\")\n\n    def graficar_historial(self):\n        \"\"\"Gráficos estáticos de evolución de cola y servidores.\"\"\"\n        # 1. Desempaquetar datos\n        tiempos = [d[0] for d in self.historia]\n        n_cola = [d[1] for d in self.historia]\n        n_ocupados = [d[2] for d in self.historia]\n\n        # 2. Configurar figura (2 subplots)\n        fig, (ax1, ax2) = plt.subplots(\n            2, 1, figsize=(10, 8), sharex=True\n        )\n\n        # --- Gráfico 1: Evolución de la Cola ---\n        ax1.step(tiempos, n_cola, where='post',\n                 color='tab:blue', linewidth=1.5)\n        ax1.fill_between(tiempos, n_cola, step='post',\n                         alpha=0.2, color='tab:blue')\n        ax1.set_ylabel('Clientes en Cola')\n        ax1.set_title(\n            f'Evolución Cola (M/M/{self.n_servidores})'\n        )\n        ax1.grid(True, linestyle='--', alpha=0.6)\n\n        # --- Gráfico 2: Uso de Servidores ---\n        ax2.step(tiempos, n_ocupados, where='post',\n                 color='tab:orange', linewidth=1.5)\n        ax2.fill_between(tiempos, n_ocupados, step='post',\n                         alpha=0.2, color='tab:orange')\n        ax2.set_ylabel('Servidores Ocupados')\n        ax2.set_xlabel('Tiempo de Simulación (horas)')\n        ax2.set_title('Ocupación de Servidores')\n        \n        # Línea de capacidad máxima\n        ax2.axhline(y=self.n_servidores, color='red',\n                    linestyle=':', label='Capacidad Max')\n        ax2.set_ylim(0, self.n_servidores + 0.5)\n        ax2.legend()\n        ax2.grid(True, linestyle='--', alpha=0.6)\n\n        plt.tight_layout()\n        plt.show()\n\nA continuación se utiliza la clase de Simulación M/M/c implementada. Si n_servidores=1 la cola crece infinitamente, esto ese produce un cuello de botella\n\n# Configurar la simulación (8 horas, lambda=10, mu=4, c=3)\nmi_simulacion = SimulacionMMC_Log(\n    tiempo_max=8.0, \n    tasa_llegada=10.0, \n    tasa_servicio=4.0, \n    n_servidores=3\n)\n\n# Correr la simulación matemática\nmi_simulacion.correr()\n\n--- Iniciando Simulación M/M/3 por 8.0 horas ---\n\n========================================\n      RESULTADOS DE LA SIMULACIÓN\n========================================\nTiempo simulado: 8.00 horas\nTotal llegadas:  76\nTotal atendidos: 74\n----------------------------------------\nLongitud prom cola (Lq): 1.1194 clientes\nTiempo prom cola (Wq): 7.07 minutos\nServidores ocupados (prom): 2.28\nUtilización (Rho): 75.95%\n========================================\n\n\n\nPara visualizar los resultados de la simulación de eventos discretos se usan gráficos de paso (step plots) dad que el estado del sistema (número en cola en espera o servidores ocupados) permanece constante entre eventos y va cambiando con cada arribo.\n\n# Generar el gráfico de pasos\nmi_simulacion.graficar_historial()\n\n\n\n\n\n\n\n\n\n\n\nParte 4 - Modelos Continuos\nPara implementar un modelo de simulación de eventos basado en un Proceso de Poisson No Homogéneo (NHPP) mediante el método de Thinning (o adelgazamiento de Lewis-Shedler), el primer paso consiste en definir una tasa mayorante constante \\(\\lambda^*\\), la cual debe ser igual o superior al valor máximo que alcanza la función de intensidad variable \\(\\lambda(t)\\) durante todo el periodo de simulación. El motor de simulación avanza generando una secuencia de tiempos de arribo “candidatos” utilizando esta tasa máxima constante, creando efectivamente un proceso de Poisson homogéneo que “sobremuestrea” la línea de tiempo con más eventos de los necesarios.\nEl segundo paso es el proceso de filtrado estocástico que da nombre al método. Para cada evento candidato generado en el instante \\(t\\), se evalúa si se conserva o se descarta mediante una prueba de aceptación-rechazo: se genera un número aleatorio uniforme \\(u \\in [0, 1]\\) y se compara con el ratio \\(\\lambda(t) / \\lambda^*\\). Si \\(u\\) es menor o igual a esta proporción, el evento se acepta y se procesa; de lo contrario, se ignora (se “adelgaza” la secuencia). De esta forma, la probabilidad de aceptar un evento es proporcional a la intensidad real en ese momento, resultando en una distribución de eventos que se ajusta fielmente a la curva de la tasa variable \\(\\lambda(t)\\).\n\nImplementación de NHPPP por Thinning\nAsí para esta simulación se diseña una función de intensidad \\(\\lambda(t)\\) que es realista para una simulación de 7 días: simula ciclos diarios (como el tráfico de una web o clientes en una tienda) con picos durante el día y valles durante la noche. El algoritmo de Thinning (o Aceptación-Rechazo) funciona en tres pasos:\n\nDominancia: Se define una tasa constante \\(\\lambda_{max}\\) que sea mayor o igual a la tasa real \\(\\lambda(t)\\) en todo momento.\nGeneración: Se generan “candidatos” a eventos usando un Proceso de Poisson Homogéneo con la tasa máxima \\(\\lambda_{max}\\).\nFiltrado (Thinning): Se acepta cada candidato como un evento real con probabilidad \\(P = \\frac{\\lambda(t)}{\\lambda_{max}}\\).\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Función de Intensidad\ndef intensity_function(t):\n    \"\"\"\n    Define la tasa de llegada lambda(t).\n    Ciclo diario (24h) con picos al mediodía.\n    \"\"\"\n    cycle = 15 * np.sin(2 * np.pi * (t - 9) / 24)\n    rate = 20 + cycle\n    return max(0, rate)\n\n# Función de Filtro\ndef simulate_nhpp_thinning(t_max, lambda_upper_bound):\n    \"\"\"\n    Simulación NHPP mediante Thinning.\n    Retorna: (lista de eventos, número total de intentos)\n    \"\"\"\n    t = 0\n    events = []\n    candidates_count = 0\n    \n    while t &lt; t_max:\n        # 1. Generar candidato (Poisson Homogéneo)\n        u1 = np.random.uniform(0, 1)\n        w = -np.log(u1) / lambda_upper_bound\n        t = t + w\n        \n        if t &gt;= t_max:\n            break\n            \n        candidates_count += 1\n            \n        # 2. Probabilidad de aceptación\n        prob_acceptance = intensity_function(t) / lambda_upper_bound\n        \n        # 3. Test de aceptación (Thinning)\n        u2 = np.random.uniform(0, 1)\n        if u2 &lt;= prob_acceptance:\n            events.append(t)\n            \n    return np.array(events), candidates_count\n\n# Generación de reporte de la simulación\ndef generar_reporte_texto(events, total_candidates, t_max, dias):\n    \"\"\"\n    Imprime un resumen estadístico de la simulación en la consola.\n    \"\"\"\n    num_events = len(events)\n    # Calcular tiempos entre llegadas (Inter-arrival times)\n    iat = np.diff(events)\n    \n    # Pre-cálculos para acortar las líneas de print\n    eficiencia = num_events / total_candidates\n    prom_global = num_events / t_max\n\n    print(\"=\" * 60)\n    print(f\" REPORTE DE SIMULACIÓN DE EVENTOS (NHPP) - {dias} DÍAS\")\n    print(\"=\" * 60)\n    \n    print(\"\\n--- MÉTRICAS GENERALES ---\")\n    print(f\"Tiempo total simulado : {t_max} horas\")\n    print(f\"Eventos generados     : {num_events}\")\n    print(f\"Candidatos totales    : {total_candidates}\")\n    print(f\"Eficiencia del Thinning: {eficiencia:.2%} \"\n          \"(Eventos aceptados / Candidatos)\")\n    print(f\"Promedio global        : {prom_global:.2f} eventos/hora\")\n\n    if len(iat) &gt; 0:\n        mean_iat = np.mean(iat)\n        print(\"\\n--- ESTADÍSTICAS DE TIEMPOS ENTRE LLEGADAS (IAT) ---\")\n        print(f\"IAT Promedio          : {mean_iat:.4f} horas \"\n              f\"({mean_iat * 60:.2f} minutos)\")\n        print(f\"IAT Mínimo            : {np.min(iat):.6f} horas\")\n        print(f\"IAT Máximo            : {np.max(iat):.4f} horas\")\n        print(f\"Desviación Estándar   : {np.std(iat):.4f}\")\n\n    print(\"\\n--- DESGLOSE DIARIO ---\")\n    # Dividimos el encabezado de la tabla para legibilidad\n    header = f\"{'Día':&lt;10} | {'Rango Horario':&lt;20} | \" \\\n             f\"{'Eventos':&lt;10} | {'Promedio (ev/h)':&lt;15}\"\n    print(header)\n    print(\"-\" * 65)\n    \n    for d in range(dias):\n        start_t = d * 24\n        end_t = (d + 1) * 24\n        \n        # Filtrar eventos que caen en este día (ruptura de línea lógica)\n        day_events = events[\n            (events &gt;= start_t) & (events &lt; end_t)\n        ]\n        \n        count = len(day_events)\n        avg = count / 24\n        \n        print(f\"Día {d+1:&lt;6} | {start_t:03d}h - {end_t:03d}h         | \"\n              f\"{count:&lt;10} | {avg:.2f}\")\n    \n    print(\"=\" * 60)\n\nA continuación estas funciones se usan en una simulación de 7 días o 168 horas:\n\n# Parámetros \nDIAS = 7\nHORAS_TOTALES = DIAS * 24\nLAMBDA_MAX = 35 \n\n# Ejecución\nevents, candidates = simulate_nhpp_thinning(HORAS_TOTALES, LAMBDA_MAX)\n\n# Generar Reporte de Texto \ngenerar_reporte_texto(events, candidates, HORAS_TOTALES, DIAS)\n\n============================================================\n REPORTE DE SIMULACIÓN DE EVENTOS (NHPP) - 7 DÍAS\n============================================================\n\n--- MÉTRICAS GENERALES ---\nTiempo total simulado : 168 horas\nEventos generados     : 3294\nCandidatos totales    : 5776\nEficiencia del Thinning: 57.03% (Eventos aceptados / Candidatos)\nPromedio global        : 19.61 eventos/hora\n\n--- ESTADÍSTICAS DE TIEMPOS ENTRE LLEGADAS (IAT) ---\nIAT Promedio          : 0.0510 horas (3.06 minutos)\nIAT Mínimo            : 0.000020 horas\nIAT Máximo            : 1.1459 horas\nDesviación Estándar   : 0.0724\n\n--- DESGLOSE DIARIO ---\nDía        | Rango Horario        | Eventos    | Promedio (ev/h)\n-----------------------------------------------------------------\nDía 1      | 000h - 024h         | 487        | 20.29\nDía 2      | 024h - 048h         | 454        | 18.92\nDía 3      | 048h - 072h         | 442        | 18.42\nDía 4      | 072h - 096h         | 479        | 19.96\nDía 5      | 096h - 120h         | 472        | 19.67\nDía 6      | 120h - 144h         | 469        | 19.54\nDía 7      | 144h - 168h         | 491        | 20.46\n============================================================\n\n\nSe visualizan los resultados de la simulación:\n\n# Visualización\nplt.figure(figsize=(15, 7))\n\nt_values = np.linspace(0, HORAS_TOTALES, 500)\nlambda_values = [intensity_function(t) for t in t_values]\n\n# Gráfico de la tasa lambda (curva continua)\nplt.plot(\n    t_values, lambda_values, \n    color='navy', lw=2, label=r'Tasa $\\lambda(t)$'\n)\n\n# Línea horizontal de Lambda Máximo\nplt.hlines(\n    LAMBDA_MAX, 0, HORAS_TOTALES, \n    colors='red', linestyles='--', alpha=0.5, \n    label=r'$\\lambda_{max}$'\n)\n\n# Líneas verticales para cada evento aceptado\nplt.vlines(\n    x=events, ymin=0, ymax=5, \n    colors='limegreen', alpha=0.4, linewidth=1, \n    label='Eventos Aceptados'\n)\n\nplt.title(f'Simulación NHPP (7 Días) - {len(events)} Eventos Totales')\nplt.xlabel('Tiempo (Horas)')\nplt.ylabel('Intensidad / Eventos')\nplt.xlim(0, HORAS_TOTALES)\n\n# Configuración de los ticks del eje X\ndias_ticks = np.arange(0, HORAS_TOTALES + 1, 24)\netiquetas_dias = [f'Día {i}' for i in range(len(dias_ticks))]\nplt.xticks(dias_ticks, etiquetas_dias)\n\nplt.grid(True, alpha=0.3)\nplt.legend(loc='upper right')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nLa visulización ilustra la evolución temporal de un Proceso de Poisson No Homogéneo (NHPP) durante un periodo de 168 horas, equivalente a siete días completos. El componente principal es la curva azul oscuro que representa la función de intensidad \\(\\lambda(t)\\), la cual exhibe un comportamiento perfectamente cíclico y sinusoidal, oscilando entre una tasa base cercana a 5 y un pico máximo de 35 eventos por hora. Sobre esta curva se proyecta una línea roja discontinua que marca la cota superior \\(\\lambda_{max}\\) (establecida en 35), la cual actúa como el techo de referencia necesario para la generación de eventos candidatos dentro del algoritmo de Thinning.\nEn la franja inferior, las líneas verticales verdes denotan los instantes exactos de los eventos finalmente aceptados por el modelo. Se observa una correlación directa entre la densidad de estas líneas y la magnitud de la función de intensidad: la concentración de eventos se vuelve densa y compacta coincidiendo con los picos de la onda sinusoidal, mientras que se dispersa notablemente durante los valles. Esta distribución visual confirma la eficacia del método de aceptación-rechazo, demostrando que la frecuencia de ocurrencia de los eventos se modula dinámicamente en función de la tasa variable \\(\\lambda(t)\\) en cada instante del tiempo.\n\n\n\nParte 5 - Gillespie SSA o Next Reaction Method\nPara implementar el algoritmo de Gillespie (SSA) en este sistema, primero se deben calcular en cada iteración las propensiones (\\(a_v\\)) que determinan la probabilidad instantánea de cada canal de reacción. Para la síntesis (orden cero), la propensión es constante, \\(a_1 = k_1 = 10\\); para la degradación (primer orden), la propensión depende del estado actual de la población, \\(a_2 = k_2 \\times [\\text{mRNA}]\\). Se calcula la propensión total \\(a_0 = a_1 + a_2\\) y se genera el tiempo hasta el próximo evento (\\(\\tau\\)) muestreando una distribución exponencial con media \\(1/a_0\\) (usualmente \\(-\\ln(u_1)/a_0\\)), lo que define cuánto tiempo transcurre en el sistema antes de que la configuración molecular cambie.\nUna vez determinado el “cuándo”, se decide el “qué” seleccionando una de las dos reacciones con probabilidad proporcional a su magnitud relativa (\\(P_{síntesis} = a_1/a_0\\) y \\(P_{degradación} = a_2/a_0\\)). Dependiendo de la reacción elegida, se actualiza el contador de moléculas de mRNA incrementándolo o decrementándolo en una unidad, se avanza el tiempo de simulación (\\(t \\leftarrow t + \\tau\\)) y, crucialmente, se recalculan las propensiones para el siguiente paso, dado que \\(a_2\\) cambiará cada vez que varíe la cantidad de mRNA, capturando así las fluctuaciones estocásticas intrínsecas del sistema.\n\nAlgoritmo de Gillespie (Método Directo)\nEsta es una implementación del Algoritmo de Gillespie (Método Directo) en Python para el sistema de nacimiento y muerte (producción y degradación de ARNm) planteado:\n\\[\\to \\text{mRNA} (k_{1}=10)\\] \\[\\text{mRNA}\\to (k_{2}=1)\\]\nBasado en esta descripción tenemos dos reacciones: 1. Producción (Transcripción): \\(\\emptyset \\xrightarrow{k_1} \\text{mRNA}\\). Tasa constante: \\(k_1 = 10\\). Esta reacción incrementa el conteo de ARNm en 1. 3. Degradación: \\(\\text{mRNA} \\xrightarrow{k_2} \\emptyset\\). Tasa dependiente de la cantidad actual: \\(k_2 = 1\\). Esta reacción disminuye el conteo de ARNm en 1.\nCabe destacar que el estado estacionario promedio esperado es \\(k_1 / k_2 = 10\\) moléculas. El estado estacionario promedio de \\(10\\) moléculas se fundamenta en el principio de equilibrio dinámico, el cual se alcanza cuando la velocidad de entrada (producción) iguala a la velocidad de salida (degradación) del sistema. Dado que la producción ocurre a una tasa constante \\(k_1\\) y la degradación es proporcional a la cantidad de moléculas presentes (\\(k_2 \\cdot \\text{mRNA}\\)), el balance se logra matemáticamente cuando \\(k_1 = k_2 \\cdot \\text{mRNA}\\); al despejar la concentración de equilibrio, se obtiene el cociente \\(k_1 / k_2\\), lo que resulta en un valor promedio de \\(10\\) moléculas para los parámetros dados.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Funcion de Simulacion\ndef gillespie_ssa(k1, k2, t_max):\n    # Inicialización\n    t = 0.0\n    # Condición inicial (puedes cambiarla)\n    mRNA = 0\n    \n    # Listas para guardar el historial (para graficar)\n    time_points = [t]\n    mRNA_counts = [mRNA]\n    \n    while t &lt; t_max:\n        # 1. Calcular las propensiones (propensities)\n        # a1: Probabilidad de producción (constante)\n        a1 = k1\n        # a2: Prob. degradación (proporcional a moléculas)\n        a2 = k2 * mRNA\n        \n        a_sum = a1 + a2\n        \n        # Si a_sum es 0, el sistema para (sin reacciones)\n        if a_sum == 0:\n            break\n            \n        # 2. Determinar tiempo hasta próxima reacción (tau)\n        # Se extrae de una distribución exponencial\n        r1 = np.random.rand()\n        tau = (1.0 / a_sum) * np.log(1.0 / r1)\n        \n        # 3. Determinar qué reacción ocurre\n        r2 = np.random.rand()\n        \n        if r2 &lt; (a1 / a_sum):\n            # Ocurre Reacción 1: Producción\n            mRNA += 1\n        else:\n            # Ocurre Reacción 2: Degradación\n            mRNA -= 1\n            \n        # 4. Actualizar tiempo y guardar estado\n        t += tau\n        time_points.append(t)\n        mRNA_counts.append(mRNA)\n        \n    return time_points, mRNA_counts\n\n# Función para Generar el Informe\ndef generar_informe_texto(tiempos, conteos, k1, k2):\n    # Convertir a numpy array para cálculos estadísticos\n    arr_conteos = np.array(conteos)\n    \n    # Cálculos estadísticos sobre la simulación\n    media_sim = np.mean(arr_conteos)\n    desv_std = np.std(arr_conteos)\n    var_sim = np.var(arr_conteos)\n    min_val = np.min(arr_conteos)\n    max_val = np.max(arr_conteos)\n    \n    total_ev = len(tiempos) - 1\n    t_final = tiempos[-1]\n    \n    # Valores Teóricos\n    media_teorica = k1 / k2\n    # En Poisson ideal, varianza es igual a la media\n    var_teorica = media_teorica \n    \n    # Cálculo del error relativo (dividido en pasos)\n    diff = abs(media_sim - media_teorica)\n    error_rel = (diff / media_teorica) * 100\n\n    # Definimos separadores para usar dentro del f-string\n    sep = \"=\" * 50\n    sub = \"-\" * 50\n\n    # Construcción del reporte usando concatenación implícita\n    # para respetar el ancho de 70 caracteres en el editor\n    informe = (\n        f\"\\n{sep}\\n\"\n        f\"SIMULACIÓN ESTOCÁSTICA (GILLESPIE SSA)\\n\"\n        f\"{sep}\\n\\n\"\n        f\"1. PARÁMETROS DEL SISTEMA\\n\"\n        f\"{sub}\\n\"\n        f\"Reacción 1 (Producción) k1 : {k1}\\n\"\n        f\"Reacción 2 (Degradación) k2: {k2}\\n\"\n        f\"Tiempo total simulado      : {t_final:.2f} u.t.\\n\"\n        f\"Total de eventos ocurridos : {total_ev}\\n\\n\"\n        f\"2. ANÁLISIS ESTADÍSTICO DE LA TRAYECTORIA\\n\"\n        f\"{sub}\\n\"\n        f\"Media observada            : {media_sim:.4f} mols\\n\"\n        f\"Desviación estándar        : {desv_std:.4f}\\n\"\n        f\"Varianza observada         : {var_sim:.4f}\\n\"\n        f\"Rango de fluctuación       : [{min_val}] - [{max_val}]\\n\\n\"\n        f\"3. VALIDACIÓN CON MODELO TEÓRICO\\n\"\n        f\"{sub}\\n\"\n        f\"Estado Estacionario Esp.   : {media_teorica:.4f} mols\\n\"\n        f\"Varianza Esperada (Poisson): {var_teorica:.4f}\\n\"\n        f\"Error Relativo (Media)     : {error_rel:.2f}%\\n\"\n    )\n    \n    return informe\n\nA continuación se usa la simulación para el sistema planteado:\n\n# Parámetros\n# Dado que se simulan ARNm, los procesos de transcripción y \n# degradación suelen medirse en minutos o horas.\nk1 = 10.0\nk2 = 1.0\nt_max = 1000.0 \n\n# Simular\ntiempos, conteos = gillespie_ssa(k1, k2, t_max)\n\n# Generar e imprimir informe\nreporte = generar_informe_texto(tiempos, conteos, k1, k2)\nprint(reporte)\n\n\n==================================================\nSIMULACIÓN ESTOCÁSTICA (GILLESPIE SSA)\n==================================================\n\n1. PARÁMETROS DEL SISTEMA\n--------------------------------------------------\nReacción 1 (Producción) k1 : 10.0\nReacción 2 (Degradación) k2: 1.0\nTiempo total simulado      : 1000.00 u.t.\nTotal de eventos ocurridos : 20185\n\n2. ANÁLISIS ESTADÍSTICO DE LA TRAYECTORIA\n--------------------------------------------------\nMedia observada            : 10.7573 mols\nDesviación estándar        : 3.3082\nVarianza observada         : 10.9444\nRango de fluctuación       : [0] - [24]\n\n3. VALIDACIÓN CON MODELO TEÓRICO\n--------------------------------------------------\nEstado Estacionario Esp.   : 10.0000 mols\nVarianza Esperada (Poisson): 10.0000\nError Relativo (Media)     : 7.57%\n\n\n\nSe visualizan los resultados de la simulación:\n\n# Visualización\nplt.figure(figsize=(10, 6))\n\n# Graficar trayectoria (step plot para saltos discretos)\nplt.step(\n    tiempos,\n    conteos,\n    where='post',\n    label='Trayectoria Estocástica (Gillespie)'\n)\n\n# Graficar la media teórica (k1 / k2)\nmedia_teorica = k1 / k2\n\nplt.axhline(\n    y=media_teorica,\n    color='r',\n    linestyle='--',\n    # Usamos .2f para evitar que el número sea muy largo\n    label=f'Media Teórica ({media_teorica:.2f})'\n)\n\nplt.title(\n    'Simulación Gillespie: Producción y Degradación de ARNm'\n)\nplt.xlabel('Tiempo')\nplt.ylabel('Número de moléculas de ARNm')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n\n\n\n\n\n\n\nLa visualización ilustra la naturaleza estocástica del sistema de producción y degradación de ARNm, donde la trayectoria azul exhibe fluctuaciones continuas y aleatorias inherentes al ruido intrínseco del proceso biológico. Se observa que, tras superar la condición inicial nula, el número de moléculas oscila dinámicamente alrededor del valor de equilibrio teórico señalado por la línea discontinua roja (10 moléculas), demostrando que, si bien el promedio temporal del sistema converge al modelo determinista, el estado instantáneo varía constantemente dentro de un rango de dispersión característico (aproximadamente entre 0 y 23 moléculas).\n\n\n\nParte Integradora - Simulación de Tráfico Aéreo\nSe propone un modelo de simulación híbrida de tráfico aéreo donde el flujo de entrada de aeronaves se gestiona mediante un Proceso de Poisson No Homogéneo (NHPP) utilizando el método de Thinning. Este componente permite modelar fielmente las curvas de demanda operativa del aeropuerto, generando llegadas estocásticas que respetan los picos horarios (horas punta) y los valles nocturnos. Estas entidades (aviones) ingresan a un sistema de colas modelado bajo la lógica M/M/1, donde la pista de aterrizaje actúa como el servidor único con tiempos de servicio exponenciales, gestionando tanto la cola de espera en el aire (holding pattern) como en tierra (taxiway).\nDe forma paralela y asíncrona, se ejecuta un motor basado en el Algoritmo de Gillespie (SSA) para simular la dinámica meteorológica. En este contexto, los estados del clima (ej. “Despejado”, “Viento Cruzado”, “Tormenta Eléctrica”) se tratan como “especies químicas” discretas que transicionan estocásticamente en función de tasas de cambio históricas (propensidades). El algoritmo de Gillespie determina los intervalos exactos de tiempo en los que el sistema permanece en cada estado climático, generando una línea de tiempo de condiciones ambientales independiente del tráfico aéreo pero estadísticamente exacta.\nLa integración de ambos modelos se realiza mediante una modulación dinámica de la tasa de servicio (\\(\\mu\\)). El estado vigente dictado por el módulo Gillespie actúa como una variable de control sobre el modelo M/M/1: cuando Gillespie transiciona a un estado de “Tormenta”, la tasa de servicio de la pista se reduce drásticamente o se anula (\\(\\mu \\to 0\\)), provocando que las operaciones de aterrizaje y despegue se aborten. Esto fuerza al sistema de colas a entrar en un régimen de saturación o desvío de entidades, permitiendo analizar no solo la congestión por volumen de tráfico, sino la resiliencia del aeropuerto ante ventanas de inoperatividad estocástica y su capacidad de recuperación (recovery rate) una vez restablecidas las condiciones favorables.\nEl pipeline de ejecución se orquesta mediante un reloj maestro que sincroniza dos generadores de eventos concurrentes: un módulo de tráfico que inyecta entidades (aeronaves) en la línea de tiempo usando NHPP por Thinning para replicar la demanda horaria, y un motor Gillespie independiente que actualiza asincrónicamente el estado global del clima (variables de entorno). Dentro del bucle principal de procesamiento (LEF), la lógica del servidor M/M/1 consulta en tiempo real el estado vigente dictado por Gillespie antes de intentar atender a una aeronave; si el motor climático indica un evento adverso (ej. “Tormenta”), se activa una interrupción que anula o penaliza drásticamente la tasa de servicio (\\(\\mu\\)), forzando la acumulación de entidades en la cola hasta que una nueva transición estocástica del clima restablezca la operatividad, permitiendo así medir el impacto sistémico de la interrupción.\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport heapq\nimport random\n\n# ==========================================\n# 1. CONFIGURACIÓN Y PARÁMETROS\n# ==========================================\nSIM_DURATION = 24.0  # Horas\nSEED = rnd_seed\n\n# Parámetros de Tráfico (NHPP)\nLAMBDA_MAX = 20.0    # Tasa máxima de llegadas (aviones/hora) para Thinning\nMU_OPERATIVO = 25.0  # Tasa de servicio de la pista (aviones/hora) en buen clima\n\n# Parámetros Climáticos (Gillespie)\n# Estado 0: Despejado, Estado 1: Tormenta\nTASA_DESPEJADO_A_TORMENTA = 0.15  # Frecuencia de aparición de tormentas\nTASA_TORMENTA_A_DESPEJADO = 0.8   # Velocidad de recuperación (duración tormenta)\n\n# Tipos de Eventos\nEVT_ARRIVAL = 0\nEVT_DEPARTURE = 1\nEVT_WEATHER = 2\n\n# Estados del Clima\nCLIMA_CLEAR = 0\nCLIMA_STORM = 1\n\nnp.random.seed(SEED)\nrandom.seed(SEED)\n\nclass HybridAirportSim:\n    def __init__(self, t_max):\n        self.t_max = t_max\n        self.clock = 0.0\n        \n        # Estado del Sistema\n        self.queue_count = 0        # Aviones en cola (aire + tierra)\n        self.server_busy = False    # Estado de la pista\n        self.weather_state = CLIMA_CLEAR\n        \n        # Gestión de Eventos (Lista de Eventos Futuros - LEF)\n        self.events = []  # Heapq\n        \n        # Control de Eventos de Salida (para poder cancelarlos)\n        self.current_departure_token = None \n        \n        # Estadísticas\n        self.stats = {\n            'arrivals': 0,\n            'completed': 0,\n            'aborted_ops': 0,  # Operaciones canceladas por clima\n            'weather_changes': 0,\n            'storm_duration': 0.0\n        }\n        \n        # Historiales para graficar (tiempo, valor)\n        self.history_occupancy = [(0.0, 0)]\n        self.history_weather = [(0.0, CLIMA_CLEAR)]\n        self.history_aborts = [] # Puntos (t, y) donde hubo abortos\n        \n    def schedule_event(self, time, event_type, token=None):\n        if time &lt;= self.t_max:\n            heapq.heappush(self.events, (time, event_type, token))\n\n    # ---------------------------------------------------------\n    # MÓDULO 1: TRÁFICO AÉREO (NHPP - Thinning Algorithm)\n    # ---------------------------------------------------------\n    def get_arrival_rate(self, t):\n        \"\"\"\n        Función de intensidad lambda(t).\n        Modela picos de tráfico a las 8am y 6pm.\n        \"\"\"\n        # Base de 5 aviones + oscilación de hasta 10 aviones\n        # t está en horas (0-24)\n        cycle = np.sin((t - 6) * np.pi / 12) ** 2  \n        rate = 5 + 15 * cycle \n        return rate\n\n    def schedule_next_arrival_nhpp(self):\n        \"\"\"Genera la próxima llegada usando Thinning.\"\"\"\n        t_curr = self.clock\n        while True:\n            # 1. Generar paso de tiempo con tasa homogénea máxima\n            u1 = random.random()\n            dt = -np.log(u1) / LAMBDA_MAX\n            t_curr += dt\n            \n            if t_curr &gt; self.t_max:\n                return # Fin de simulación\n            \n            # 2. Test de aceptación/rechazo (Thinning)\n            lambda_t = self.get_arrival_rate(t_curr)\n            prob_accept = lambda_t / LAMBDA_MAX\n            \n            if random.random() &lt;= prob_accept:\n                self.schedule_event(t_curr, EVT_ARRIVAL)\n                break\n\n    # ---------------------------------------------------------\n    # MÓDULO 2: MOTOR CLIMÁTICO (GILLESPIE SSA)\n    # ---------------------------------------------------------\n    def schedule_next_weather_change(self):\n        \"\"\"\n        Determina el tiempo hasta el próximo cambio de clima\n        basado en propensiones estocásticas (Gillespie).\n        \"\"\"\n        # Determinar propensión (a0) según estado actual\n        if self.weather_state == CLIMA_CLEAR:\n            a0 = TASA_DESPEJADO_A_TORMENTA\n        else:\n            a0 = TASA_TORMENTA_A_DESPEJADO\n            \n        # Tiempo hasta la próxima reacción (tau)\n        if a0 &gt; 0:\n            r = random.random()\n            tau = (1.0 / a0) * np.log(1.0 / r)\n            next_time = self.clock + tau\n            self.schedule_event(next_time, EVT_WEATHER)\n\n    # ---------------------------------------------------------\n    # MÓDULO 3: NÚCLEO DE SIMULACIÓN Y LÓGICA DE CONTROL\n    # ---------------------------------------------------------\n    def run(self):\n        # Inicialización\n        self.schedule_next_arrival_nhpp()\n        self.schedule_next_weather_change()\n        \n        print(f\"--- Iniciando Simulación Híbrida ({self.t_max}h) ---\")\n        \n        while self.events:\n            time, type, token = heapq.heappop(self.events)\n            \n            # Avanzar reloj\n            self.clock = time\n            \n            # Registrar estado para gráficos (Step plot)\n            curr_occupancy = self.queue_count + (1 if self.server_busy else 0)\n            self.history_occupancy.append((self.clock, curr_occupancy))\n            self.history_weather.append((self.clock, self.weather_state))\n            \n            # Despachador de eventos\n            if type == EVT_ARRIVAL:\n                self.handle_arrival()\n            elif type == EVT_DEPARTURE:\n                self.handle_departure(token)\n            elif type == EVT_WEATHER:\n                self.handle_weather_change()\n                \n        self.generate_report()\n        self.plot_results()\n\n    def handle_arrival(self):\n        self.stats['arrivals'] += 1\n        self.schedule_next_arrival_nhpp() # Programar siguiente recursivamente\n        \n        if not self.server_busy and self.weather_state == CLIMA_CLEAR:\n            # Pista libre y buen clima: Aterrizaje inmediato\n            self.server_busy = True\n            self.schedule_departure()\n        else:\n            # Pista ocupada O clima adverso: A la cola (Holding)\n            self.queue_count += 1\n\n    def schedule_departure(self):\n        # Generar tiempo de servicio exponencial\n        service_time = random.expovariate(MU_OPERATIVO)\n        \n        # Crear un token único para este servicio\n        # Esto permite invalidar el evento si el clima cambia\n        token = random.randint(0, 1e9)\n        self.current_departure_token = token\n        \n        self.schedule_event(self.clock + service_time, EVT_DEPARTURE, token)\n\n    def handle_departure(self, token):\n        # Verificar si el token es válido (no fue abortado)\n        if token != self.current_departure_token:\n            return # Evento ignorado (fue cancelado por clima)\n            \n        self.stats['completed'] += 1\n        self.server_busy = False\n        self.current_departure_token = None\n        \n        # Intentar procesar siguiente en cola SI el clima lo permite\n        if self.queue_count &gt; 0 and self.weather_state == CLIMA_CLEAR:\n            self.queue_count -= 1\n            self.server_busy = True\n            self.schedule_departure()\n\n    def handle_weather_change(self):\n        self.stats['weather_changes'] += 1\n        \n        # Alternar estado (0 -&gt; 1, 1 -&gt; 0)\n        self.weather_state = 1 - self.weather_state\n        \n        # LÓGICA DE INTERRUPCIÓN / RECUPERACIÓN\n        if self.weather_state == CLIMA_STORM:\n            # Transición a TORMENTA\n            if self.server_busy:\n                # ABORTAR OPERACIÓN\n                # La aeronave debe hacer 'go-around' y volver a cola\n                self.stats['aborted_ops'] += 1\n                self.server_busy = False\n                self.queue_count += 1 # Regresa a la cola\n                \n                # Invalida el evento de salida pendiente\n                self.current_departure_token = None \n                \n                # Guardar punto para gráfico\n                self.history_aborts.append(\n                    (self.clock, self.queue_count + 1)\n                )\n                \n        elif self.weather_state == CLIMA_CLEAR:\n            # Transición a DESPEJADO (Recuperación)\n            # Si hay cola, reiniciar operaciones inmediatamente\n            can_resume = (self.queue_count &gt; 0 and \n                          not self.server_busy)\n                          \n            if can_resume:\n                self.queue_count -= 1\n                self.server_busy = True\n                self.schedule_departure()\n\n        # Programar siguiente cambio de clima (Gillespie)\n        self.schedule_next_weather_change()\n\n    # ---------------------------------------------------------\n    # GENERACIÓN DE REPORTES Y GRÁFICOS\n    # ---------------------------------------------------------\n    def generate_report(self):\n        # Calcular tiempo total en tormenta\n        t_storm = 0\n        # Alias para acortar líneas\n        hist = self.history_weather\n        \n        for i in range(1, len(hist)):\n            # Desglose de cálculo de tiempo\n            t_curr = hist[i][0]\n            t_prev = hist[i-1][0]\n            t_delta = t_curr - t_prev\n            \n            state = hist[i-1][1]\n            if state == CLIMA_STORM:\n                t_storm += t_delta\n        \n        # Pre-cálculo de porcentaje para limpiar el f-string\n        pct_storm = (t_storm / self.t_max) * 100\n\n        print(\"\\n\" + \"=\"*50)\n        print(\"REPORTE DE SIMULACIÓN AEROPORTUARIA HÍBRIDA\")\n        print(\"=\"*50)\n        \n        print(f\"Duración Simulación     : {self.t_max} horas\")\n        \n        print(f\"Total Llegadas (NHPP)   : \"\n              f\"{self.stats['arrivals']}\")\n              \n        print(f\"Aterrizajes Exitosos    : \"\n              f\"{self.stats['completed']}\")\n              \n        print(f\"Operaciones Abortadas   : \"\n              f\"{self.stats['aborted_ops']} (Go-arounds)\")\n              \n        print(\"-\" * 50)\n        print(\"METEOROLOGÍA (GILLESPIE SSA)\")\n        \n        print(f\"Eventos de Cambio Clima : \"\n              f\"{self.stats['weather_changes']}\")\n              \n        print(f\"Tiempo en Tormenta      : {t_storm:.2f} h \"\n              f\"({pct_storm:.1f}%)\")\n              \n        print(\"=\"*50 + \"\\n\")\n\n    def plot_results(self):\n        # Desempaquetar datos para historial de ocupación\n        times = [x[0] for x in self.history_occupancy]\n        occupancy = [x[1] for x in self.history_occupancy]\n        \n        # Procesar clima para rellenar áreas (fill_between)\n        w_times = [x[0] for x in self.history_weather]\n        w_states = [x[1] for x in self.history_weather]\n        \n        plt.figure(figsize=(12, 6))\n        \n        # 1. Dibujar Áreas de Tormenta\n        for i in range(len(w_times)-1):\n            t_start = w_times[i]\n            t_end = w_times[i+1]\n            state = w_states[i]\n            \n            if state == CLIMA_STORM:\n                plt.axvspan(\n                    t_start, t_end, \n                    color='red', alpha=0.2, lw=0\n                )\n\n        # Etiqueta fantasma para la leyenda del clima\n        plt.axvspan(\n            -1, -0.1, color='red', alpha=0.2, \n            label='Condición: Tormenta (Pista Cerrada)'\n        )\n\n        # 2. Curva de Ocupación\n        plt.step(\n            times, occupancy, where='post', \n            color='#003366', lw=2, \n            label='Ocupación (Cola + Pista)'\n        )\n        \n        # 3. Marcar Abortos\n        if self.history_aborts:\n            ab_t = [x[0] for x in self.history_aborts]\n            ab_y = [x[1] for x in self.history_aborts]\n            plt.scatter(\n                ab_t, ab_y, color='red', \n                marker='x', s=100, zorder=5, \n                label='Operación Abortada'\n            )\n\n        # 4. Curva de Demanda Teórica (Referencia)\n        t_ref = np.linspace(0, self.t_max, 200)\n        lambda_ref = [\n            self.get_arrival_rate(t) for t in t_ref\n        ]\n        \n        # Normalización visual\n        mx_ref = max(lambda_ref) if lambda_ref else 0\n        mx_occ = max(occupancy) if occupancy else 0\n        \n        scale_factor = 1\n        if mx_ref &gt; 0:\n            scale_factor = mx_occ / mx_ref\n\n        # Graficar perfil escalado\n        plt.plot(\n            t_ref, \n            np.array(lambda_ref) * 0.5, \n            '--', color='green', alpha=0.5, \n            label='Perfil Demanda (NHPP) (Escalado)'\n        )\n\n        # Construcción del título\n        title_str = (\n            f\"Dinámica Aeroportuaria: Tráfico NHPP vs \"\n            f\"Clima Gillespie\\n\"\n            f\"({self.stats['aborted_ops']} \"\n            f\"operaciones abortadas)\"\n        )\n\n        plt.title(title_str, fontsize=14)\n        plt.xlabel('Hora del día', fontsize=12)\n        plt.ylabel(\n            'Cantidad de Aeronaves en Sistema', \n            fontsize=12\n        )\n        plt.legend(loc='upper left')\n        plt.grid(True, linestyle='--', alpha=0.5)\n        plt.xlim(0, self.t_max)\n        plt.ylim(bottom=0)\n        \n        plt.tight_layout()\n        plt.show()\n\n# ==========================================\n# EJECUCIÓN\n# ==========================================\nsim = HybridAirportSim(t_max=SIM_DURATION)\nsim.run()\n\n--- Iniciando Simulación Híbrida (24.0h) ---\n\n==================================================\nREPORTE DE SIMULACIÓN AEROPORTUARIA HÍBRIDA\n==================================================\nDuración Simulación     : 24.0 horas\nTotal Llegadas (NHPP)   : 304\nAterrizajes Exitosos    : 303\nOperaciones Abortadas   : 1 (Go-arounds)\n--------------------------------------------------\nMETEOROLOGÍA (GILLESPIE SSA)\nEventos de Cambio Clima : 6\nTiempo en Tormenta      : 2.84 h (11.8%)\n==================================================\n\n\n\n\n\n\n\n\n\n\n\n\nUso de Inteligencia Artificial\nEn este trabajo se utilizó inteligencia artificial (Gemini) para:\n\nTransformar código base de R a Python\nFormatear gráficos\nFormatear código para que no ocupe más de 70 caracteres (restricción de renderizado de Quarto)\nRevisar estilo de la redacción\n\n\n\nAnexo: Código base en Python\n\n# Código base\n# Linear Congruential Generator (LGC)\n\ndef lcg(n, seed=123, a=1103515245, c=12345, m=2**31):\n    x = seed\n    seq = []\n    for _ in range(n):\n        x = (a * x + c) % m\n        seq.append(x/m)\n    return seq\n\nalea = lcg(10)\nfor i in range(len(alea)):\n    print(alea[i])\n\n0.20531828328967094\n0.6873863865621388\n0.7767890496179461\n0.4024707484059036\n0.5324797946959734\n0.10148253152146935\n0.6351402262225747\n0.34936570515856147\n0.7226534709334373\n0.027218241710215807\n\n\n\n# Código base\n# Estimación de Pi por Monte Carlo\n\nimport numpy as np\n\nN = 100000\nu1 = np.random.uniform(0, 1, N)\nu2 = np.random.uniform(0, 1, N)\npi_est = 4 * np.mean(u1**2 + u2**2 &lt;= 1)\n\nprint(f\"Valor estimado de pi: {pi_est}\")\n\nValor estimado de pi: 3.14836\n\n\n\n# Código base\n# Implementación Metropolis–Hastings\n\nimport numpy as np\nfrom scipy.stats import binom\n\ndef mh(n_iter=5000, start=0.5, prop_sd=0.1):\n    # Inicializar la cadena (array lleno de ceros)\n    theta = np.zeros(n_iter)\n    theta[0] = start\n    \n    # Bucle desde el segundo elemento (índice 1) hasta el final\n    for t in range(1, n_iter):\n        # Propuesta: Distribución normal centrada en el theta anterior\n        # Equivalente en R: rnorm(1, theta[t-1], prop_sd)\n        prop = np.random.normal(loc=theta[t-1], scale=prop_sd)\n        \n        # Verificación de límites (Prior Uniforme Implícito [0,1])\n        # Si la propuesta se sale del rango [0, 1], se rechaza inmediatamente\n        if prop &lt; 0 or prop &gt; 1:\n            theta[t] = theta[t-1]\n        else:\n            # Calcular la Verosimilitud (Likelihood) usando la función \n            # de masa de probabilidad\n            # Equivalente en R: dbinom(7, 10, prob)\n            # * 1 representa el Prior (Uniforme)\n            num = binom.pmf(k=7, n=10, p=prop) * 1      \n            den = binom.pmf(k=7, n=10, p=theta[t-1]) * 1\n            \n            # Probabilidad de aceptación (alpha)\n            ratio = num / den\n            alpha = min(1, ratio)\n            \n            # Paso de Aceptación o Rechazo\n            # Generamos un número aleatorio uniforme \n            # y lo comparamos con alpha\n            if np.random.uniform() &lt; alpha:\n                # Aceptar la propuesta\n                theta[t] = prop     \n            else:\n                # Rechazar y mantener el valor anterior\n                theta[t] = theta[t-1] \n                \n    return theta\n\nchain = mh()\nprint(f\"Media Posterior Estimada: {np.mean(chain):.4f}\")\n\nMedia Posterior Estimada: 0.6778\n\n\n\n# Codigo base \n# Simulación de Eventos Discretos (M/M/1 o M/M/c)\n\nimport numpy as np\n\ndef simulate_mm1(lam, mu, T_max):\n    # Nota: 'lambda' es una palabra reservada en Python, usamos 'lam'\n    t = 0.0\n    n = 0\n    \n    # R usa la tasa (rate) para rexp: rexp(1, lambda)\n    # Numpy usa la escala (scale = 1/rate): exponential(1/lam)\n    t_arr = np.random.exponential(scale=1/lam)\n    t_dep = float('inf')  # Infinito en Python\n    \n    arrivals = 0\n    departures = 0\n    wait_times = []  \n    \n    while t &lt; T_max:\n        if t_arr &lt; t_dep:\n            # --- Evento de Llegada ---\n            t = t_arr\n            n += 1\n            arrivals += 1\n            \n            # Si el servidor estaba libre (n=1 tras la llegada)\n            # se programa servicio\n            if n == 1:\n                t_dep = t + np.random.exponential(scale=1/mu)\n            \n            # Programar la siguiente llegada\n            t_arr = t + np.random.exponential(scale=1/lam)\n            \n        else:\n            # Evento de Salida\n            t = t_dep\n            n -= 1\n            departures += 1\n            # Se agrega el tiempo a la lista\n            wait_times.append(t_dep) \n            \n            if n &gt; 0:\n                # Si quedan clientes, programar la siguiente salida\n                t_dep = t + np.random.exponential(scale=1/mu)\n            else:\n                # Si no hay nadie, la próxima salida es \"infinita\"\n                t_dep = float('inf')\n    \n    # Se devuelve un diccionario con los tiempos\n    return {\n        \"arrivals\": arrivals, \n        \"departures\": departures, \n        \"wait_times\": wait_times\n    }\n\n# Lambda = 2 clientes/min, Mu = 3 clientes/min, Tiempo = 100 min\nres = simulate_mm1(lam=2, mu=3, T_max=100)\n\nprint(f\"Llegadas totales: {res['arrivals']}\")\nprint(f\"Salidas totales: {res['departures']}\")\nprint(\"Últimos 5 tiempos de salida:\")\n\nfor i in range(len(res['wait_times'])-5,len(res['wait_times'])):\n    print(res['wait_times'][i])\n\nLlegadas totales: 215\nSalidas totales: 215\nÚltimos 5 tiempos de salida:\n98.43347389754513\n98.50944958825472\n99.40263056754019\n99.71489988562641\n100.03483812961011\n\n\n\n# Codigo base\n# Implementación Gillespie SSA\n\nimport numpy as np\nimport pandas as pd\n\ndef gillespie(Tmax, k1=10, k2=1):\n    t = 0.0\n    X = 0\n    \n    # Listas para almacenar el historial\n    ts = [t]\n    xs = [X]\n    \n    while t &lt; Tmax:\n        # Cálculo de propensiones\n        a1 = k1\n        a2 = k2 * X\n        a0 = a1 + a2\n        \n        # Si la propensión total es 0, el sistema se detiene\n        if a0 == 0:\n            break\n            \n        # 1. Generar tiempo hasta el próximo evento (tau)\n        # R: -log(runif(1)) / a0 \n        # Esto es matemáticamente generar una variable \n        # aleatoria Exponencial con tasa a0\n        tau = np.random.exponential(scale=1/a0)\n        \n        # 2. Determinar qué evento ocurre\n        r2 = np.random.uniform()\n        \n        if r2 * a0 &lt; a1:\n            # Evento 1: Nacimiento / Producción\n            X += 1\n        else:\n            # Evento 2: Muerte / Degradación\n            X = max(0, X - 1)\n            \n        # Actualizar tiempo y almacenar estado\n        t += tau\n        ts.append(t)\n        xs.append(X)\n        \n    # Devolvemos un DataFrame de Pandas \n    return pd.DataFrame({'time': ts, 'X': xs})\n\ndf_result = gillespie(Tmax=50)\n\n# Mostrar las primeras 5 filas\nprint(df_result.head())\n\n       time  X\n0  0.000000  0\n1  0.031461  1\n2  0.052792  2\n3  0.214520  3\n4  0.226669  4"
  }
]